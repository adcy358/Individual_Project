{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cac253a-6012-49c1-b612-d4f10f8052fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import argparse\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169b946-20e6-430f-a0a0-8f9c416ab941",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ec1609-515c-4041-a4db-6e5d644e4b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leopoldo Lugones</td>\n",
       "      <td>\\n\\nEn el parque confuso\\nQue con lánguidas br...</td>\n",
       "      <td>LA MUERTE DE LA LUNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marilina Rébora</td>\n",
       "      <td>\\n\\nPorque si tú no velas, vendré como ladrón;...</td>\n",
       "      <td>PORQUE SI TÚ NO VELAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonio Colinas</td>\n",
       "      <td>\\n\\nPequeña de mis sueños, por tu piel las pal...</td>\n",
       "      <td>POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>José María Hinojosa</td>\n",
       "      <td>\\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...</td>\n",
       "      <td>SENCILLEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rubén Izaguirre Fiallos</td>\n",
       "      <td>Naciste en Armenia,\\npero te fuiste a vivir al...</td>\n",
       "      <td>Breve Carta a Consuelo Suncín</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author                                            content  \\\n",
       "0         Leopoldo Lugones  \\n\\nEn el parque confuso\\nQue con lánguidas br...   \n",
       "1          Marilina Rébora  \\n\\nPorque si tú no velas, vendré como ladrón;...   \n",
       "2          Antonio Colinas  \\n\\nPequeña de mis sueños, por tu piel las pal...   \n",
       "3      José María Hinojosa  \\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...   \n",
       "4  Rubén Izaguirre Fiallos  Naciste en Armenia,\\npero te fuiste a vivir al...   \n",
       "\n",
       "                                   title  \n",
       "0                   LA MUERTE DE LA LUNA  \n",
       "1                  PORQUE SI TÚ NO VELAS  \n",
       "2  POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ  \n",
       "3                              SENCILLEZ  \n",
       "4          Breve Carta a Consuelo Suncín  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/poems.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851362a2-d484-4977-a5c3-a07d6f4e9991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poems:  5131\n"
     ]
    }
   ],
   "source": [
    "print('Poems: ', data['title'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2076206b-22ff-41b1-a1e5-c1c46919962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pablo Neruda                     357\n",
       "Luis de Góngora                  218\n",
       "Mario Benedetti                  167\n",
       "Federico García Lorca            134\n",
       "Ramón López Velarde              126\n",
       "                                ... \n",
       "Delmira Agustini                   1\n",
       "Gioconda Belli                     1\n",
       "Antonio Plaza Llamas               1\n",
       "Manuel Bretón de los Herreros      1\n",
       "Meira Delmar                       1\n",
       "Name: author, Length: 267, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd49492-50bf-40ff-9f3c-3b33a76b7f2b",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b466e5-a39f-4b17-bbb6-05999bb17c4e",
   "metadata": {},
   "source": [
    "We need to remove: \n",
    "- **punctuations** \n",
    "- **lower casing** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67efca9-a595-49fb-817f-14fc73b05f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with a sample \n",
    "sample_poem = data.content[:200]\n",
    "sent_corpus = [line.lower() for poem in sample_poem for line in str(poem).split(\"\\n\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36835bed-9151-4977-85c3-b47f781790b1",
   "metadata": {},
   "source": [
    "By loading the `es_core_news_sm model`, you can perform various NLP tasks on Spanish text using the functionalities provided by spaCy, including **tokenization** specific to the Spanish language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c605d32f-48b2-4be2-b154-925d20e024cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('spacy', language='es_core_news_sm')\n",
    "list_sent_corpus = [tokenizer(x) for x in sent_corpus if x != ''] # remove the spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b1f2af-3931-49d9-a044-d3556d728ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 5410\n"
     ]
    }
   ],
   "source": [
    "print('Number of sentences:' , len(list_sent_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b1d4c3-e369-4106-8dfb-43a7afc79f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(st_text, start_token, end_token): \n",
    "    l=[]\n",
    "    for s in st_text: # loop through each sentence\n",
    "        s = [x for x in s if x.isalnum()]\n",
    "        s.insert(0, start_token) # insert start/end tokens\n",
    "        s.append(end_token)\n",
    "        l.extend(s)  \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea30b0ee-aace-4a88-8df5-09b219116dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus = tokens_to_text(list_sent_corpus, '<SOS>', '<EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb01d99-0a84-499f-b6b4-73e7231ebe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in the corpus: 41345\n"
     ]
    }
   ],
   "source": [
    "print(\"Words in the corpus:\", len(word_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2abb44-76e4-441e-bcfa-bed592d84986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>', 'en', 'el', 'parque', 'confuso', '<EOS>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_corpus[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7db384b-b00e-4baa-8450-bd4efd6ec77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens:  7506\n"
     ]
    }
   ],
   "source": [
    "word_count = Counter(word_corpus)\n",
    "sorted_word_count = sorted(word_count, key=word_count.get, reverse=True)\n",
    "print('Number of unique tokens: ', len(sorted_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2814b801-b65d-49b9-9dbd-820082c433e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<SOS>', 5410), ('<EOS>', 5410)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7fce7f-f243-48b9-8cec-832822ea8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index: word for index, word in enumerate(sorted_word_count)}\n",
    "# {word: index}\n",
    "word_to_index = {word: index for index, word in enumerate(sorted_word_count)}\n",
    "\n",
    "words_indexes = [word_to_index[w] for w in word_corpus] # word_corpus with the index of the words instead of the words themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e834b2f5-bae3-4236-a6d0-e9d4dee3cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41345\n"
     ]
    }
   ],
   "source": [
    "print(len(words_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f263ab89-5950-4e1c-8fb9-1dc89a776c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   0,    7,    5, 2449, 1375]), tensor([   7,    5, 2449, 1375,    1]))\n",
      "Vocab: 7506\n"
     ]
    }
   ],
   "source": [
    "DIR_PATH = \"dataset/poems.csv\"\n",
    "START_TOKEN = \"<SOV>\" # start of verse\n",
    "END_TOKEN = \"<EOV>\" # end of verse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--max-epochs', type=int, default=0)\n",
    "parser.add_argument('--batch-size', type=int, default=256)\n",
    "parser.add_argument('--sequence_length', type=int, default=5)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "dataset = SpanishPoemsDataset(DIR_PATH, START_TOKEN, END_TOKEN, args)\n",
    "print(dataset.__getitem__(0))\n",
    "print('Vocab:', len(dataset.unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41966d5e-addb-4fcd-80f4-52d92c05bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   7,    5, 2449, 1375,    1]), tensor([   5, 2449, 1375,    1,    0]))\n",
      "(tensor([   5, 2449, 1375,    1,    0]), tensor([2449, 1375,    1,    0,    6]))\n",
      "(tensor([2449, 1375,    1,    0,    6]), tensor([1375,    1,    0,    6,   15]))\n",
      "(tensor([1375,    1,    0,    6,   15]), tensor([   1,    0,    6,   15, 2450]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(dataset.__getitem__(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
