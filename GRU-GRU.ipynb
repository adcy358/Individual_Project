{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20156c1f-1f77-4364-a120-204f33048f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from dataset import *\n",
    "from models import * \n",
    "from generation import *\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e45a30f-848f-423b-bfa4-de13de4fcd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2449, 1375,    1,    0,    6,   15, 2450, 2451,    5,   66]), tensor([1375,    1,    0,    6,   15, 2450, 2451,    5,   66, 2452]))\n",
      "Vocab: 7506\n"
     ]
    }
   ],
   "source": [
    "DIR_PATH = \"dataset/poems.csv\"\n",
    "SOV_TOKEN = \"<SOV>\" # start of verse\n",
    "EOV_TOKEN = \"<EOV>\" # end of verse\n",
    "encoder_ckpt = \"saved_models/encoder_1.pt\"\n",
    "decoder_ckpt = \"saved_models/decoder_1.pt\"\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--max_epochs', type=int, default=40)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--sequence_length', type=int, default=10)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# Define the dataset and dataloader\n",
    "dataset = SpanishPoemsDataset(DIR_PATH, SOV_TOKEN, EOV_TOKEN, args)\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "print(dataset.__getitem__(3))\n",
    "print('Vocab:', len(dataset.unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a882cc-73ce-4a38-9ce3-27136640501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "input_size = len(dataset.unique_words) # size of the vocabulary for the input sequence\n",
    "output_size = len(dataset.unique_words) # size of the vocabulary for the target sequence\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "batch_size = args.batch_size\n",
    "sequence_length = args.sequence_length\n",
    "num_epochs = args.max_epochs\n",
    "learning_rate = 0.001\n",
    "save_epochs = 2\n",
    "\n",
    "# Instantiate the encoder and decoder\n",
    "encoder = GRUEncoder(input_size, hidden_size, num_layers)\n",
    "decoder = GRUDecoder(hidden_size, output_size, num_layers)\n",
    "\n",
    "# Define the loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84d25b-6dc9-496b-a318-36e8580e8e87",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b83de43-5eef-468b-a7e0-160d2c7ff48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   5%|▍         | 16/323 [00:05<01:47,  2.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_228463/3172567308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "start_time = time.time()\n",
    "loss_history = []\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        batch_inputs = batch_inputs\n",
    "        batch_targets = batch_targets\n",
    "\n",
    "        # Initialize the hidden state of the encoder\n",
    "        hidden = encoder.init_hidden(sequence_length)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass - Encoder\n",
    "        encoder_outputs, hidden = encoder(batch_inputs, hidden)\n",
    "\n",
    "        # Initialize the hidden state of the decoder with the final encoder hidden state\n",
    "        decoder_hidden = hidden[:, 1:sequence_length, :].contiguous()\n",
    "\n",
    "        # Prepare the input and target sequences for the decoder\n",
    "        decoder_inputs = batch_targets[:, :-1] \n",
    "        decoder_targets = batch_targets[:, 1:]\n",
    "\n",
    "        # Forward pass - Decoder\n",
    "        decoder_outputs, _ = decoder(decoder_inputs, decoder_hidden)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(decoder_outputs.reshape(-1, output_size), decoder_targets.reshape(-1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss_history.append(loss.item())\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    if epoch % save_epochs == 0:\n",
    "        print(\"-> Saving checkpoint\") \n",
    "        torch.save(encoder.state_dict(), encoder_ckpt)\n",
    "        torch.save(decoder.state_dict(), decoder_ckpt)\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: \", elapsed_time/3600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de053455-8db4-42e0-a57b-76c3584ee3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 25\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(len(loss_history)), loss_history, label=\"Model_1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Encoder: GRU - Decoder: GRU\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"loss_512.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dce991-fe97-4bc2-96ba-385728e41b90",
   "metadata": {},
   "source": [
    "# GENERATE POEM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7aa2167-7fcd-44f2-9b38-84dd7244965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "entre lentos pescados\n",
      "sobrevuelan nuestros cuerpos\n",
      "dice ven conmigo\n",
      "tú eres la cabeza\n",
      "cuando los ojos y mi vida es que este camino\n",
      "no hay angustia comparable a no respirarte\n",
      "no verte\n",
      "pensar tú y todo\n",
      "Perplexity:  13.702206871289045\n"
     ]
    }
   ],
   "source": [
    "poem, perplexity = generate_poem_GRU(\n",
    "    encoder, decoder, dataset, \n",
    "    0, 1, max_length=50, temperature=0.8, top_k=10, \n",
    "    encoder_type='GRU', \n",
    "    encoder_ckpt=encoder_ckpt, \n",
    "    decoder_ckpt=decoder_ckpt\n",
    ")\n",
    "\n",
    "print('')\n",
    "print(poem)\n",
    "print('Perplexity: ', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55467f-4fca-4959-a623-633fab477376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
